# Experiment configuration for Fake-or-Real (FoR) 2-second dataset
# Task: Binary classification of synthetic vs. real speech (deepfake detection)

[EXP]
root = results
name = exp_for2sec_os_xgb
runs = 1
epochs = 1
save = True

[DATA]
# Using pre-defined train/dev/test splits from the dataset
databases = ['train', 'dev', 'test']

train = ./data/for-2sec/for-2sec_train.csv
train.type = csv
train.absolute_path = False
train.split_strategy = train

dev = ./data/for-2sec/for-2sec_dev.csv
dev.type = csv
dev.absolute_path = False
dev.split_strategy = train

test = ./data/for-2sec/for-2sec_test.csv
test.type = csv
test.absolute_path = False
test.split_strategy = test

# Target variable and class labels
target = label
labels = ['fake', 'real']

[FEATS]
# OpenSmile features are effective for detecting synthetic speech artifacts
# They capture prosodic, spectral, and voice quality features
type = ['os']
scale = standard

[MODEL]
# XGBoost performs well for binary classification tasks
# and is robust to the characteristics of deepfake detection
type = xgb
measure = eer 

[PLOT]
# Enable confusion matrix and other performance visualizations
best_model = True
