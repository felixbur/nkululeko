# Experiment configuration for E-SERAVD dataset
# Indonesian Speech Emotion Recognition (SER) corpus
# 1,200 recordings from 6 speakers
# 4 emotions: angry, sad, neutral, happy

[EXP]
root = ./
name = results/exp_eseravd_os_xgb
runs = 1
epochs = 1
save = True

[DATA]
# Using pre-generated train/dev/test splits (speaker-independent)
databases = ['train', 'dev', 'test']

train = ./data/e-seravd/e-seravd_train.csv
train.type = csv
train.absolute_path = False
train.split_strategy = train
train.audio_path = E-SERAVD/

dev = ./data/e-seravd/e-seravd_dev.csv
dev.type = csv
dev.absolute_path = False
dev.split_strategy = train
dev.audio_path = E-SERAVD/

test = ./data/e-seravd/e-seravd_test.csv
test.type = csv
test.absolute_path = False
test.split_strategy = test
test.audio_path = E-SERAVD/

# Target variable and class labels
target = emotion
labels = ['angry', 'sad', 'neutral', 'happy']

[FEATS]
# OpenSmile features for emotion recognition
type = ['os']
scale = standard

[MODEL]
# XGBoost with optimized hyperparameters
type = xgb
# Increase model complexity to capture speaker variability
n_estimators = 300
max_depth = 8
learning_rate = 0.1
# Regularization to prevent overfitting
min_child_weight = 3
gamma = 0.1
subsample = 0.8
colsample_bytree = 0.8

[PLOT]
# Enable confusion matrix and other visualizations
best_model = True
